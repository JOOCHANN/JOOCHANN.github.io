<!DOCTYPE html><html lang="ko-KR" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="layout-lang" content="ko-KR"><meta name="day-prompt" content="d ago"><meta name="hour-prompt" content="hr ago"><meta name="minute-prompt" content="min ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.2.1" /><meta property="og:title" content="Paper Review. Bidirectional LSTM-CRF Models for Sequence Tagging@arXiv’ 2015" /><meta name="author" content="JooChan Park" /><meta property="og:locale" content="ko_KR" /><meta name="description" content="Paper link" /><meta property="og:description" content="Paper link" /><link rel="canonical" href="https://joochann.github.io/posts/Bidirectional-LSTM-CRF-Models-for-Sequence-Tagging/" /><meta property="og:url" content="https://joochann.github.io/posts/Bidirectional-LSTM-CRF-Models-for-Sequence-Tagging/" /><meta property="og:site_name" content="CV Researcher" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-09-08T14:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Paper Review. Bidirectional LSTM-CRF Models for Sequence Tagging@arXiv’ 2015" /><meta name="twitter:site" content="@twitter_username" /><meta name="twitter:creator" content="@JooChan Park" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"JooChan Park"},"dateModified":"2021-07-30T01:05:24+09:00","datePublished":"2020-09-08T14:00:00+09:00","description":"Paper link","headline":"Paper Review. Bidirectional LSTM-CRF Models for Sequence Tagging@arXiv’ 2015","mainEntityOfPage":{"@type":"WebPage","@id":"https://joochann.github.io/posts/Bidirectional-LSTM-CRF-Models-for-Sequence-Tagging/"},"url":"https://joochann.github.io/posts/Bidirectional-LSTM-CRF-Models-for-Sequence-Tagging/"}</script><title>Paper Review. Bidirectional LSTM-CRF Models for Sequence Tagging@arXiv' 2015 | CV Researcher</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="CV Researcher"><meta name="application-name" content="CV Researcher"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang=""><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/my_img.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">CV Researcher</a></div><div class="site-subtitle font-italic">Wear Your Failure As A Badge Of Honour</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about-me/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT-ME</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/JOOCHANN" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['green261535','gmail.com'].join('@')" aria-label="email" class="order-4" > <i class="fas fa-envelope"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Paper Review. Bidirectional LSTM-CRF Models for Sequence Tagging@arXiv' 2015</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Paper Review. Bidirectional LSTM-CRF Models for Sequence Tagging@arXiv' 2015</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> JooChan Park </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Tue, Sep 8, 2020, 2:00 PM +0900" >Sep 8, 2020<i class="unloaded">2020-09-08T14:00:00+09:00</i> </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Fri, Jul 30, 2021, 1:05 AM +0900" >Jul 30, 2021<i class="unloaded">2021-07-30T01:05:24+09:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="218 words">1 min read</span></div></div><div class="post-content"><ul><li><a href="https://arxiv.org/abs/1508.01991">Paper link</a></ul><h2 id="abstract"><strong>Abstract</strong></h2><ul><li><p>LSTM 레이어와 CRF 레이어를 이용하여 LSTM-CRF 모델을 만듦</p><li><p>BI-LSTM 레이어와 CRF 레이어를 이용하여 BI-LSTM-CRF 모델을 만듦</p><li><p>BI-LSTM-CRF 모델을 이용하면 POS tagging태스크에서 높은 성능을 도달할 수 있음</p></ul><h2 id="introduction"><strong>Introduction</strong></h2><h3 id="crf란">CRF란</h3><p><img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\1.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\2.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\3.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\4.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\5.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\6.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\7.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\8.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\9.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\10.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\11.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\12.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\13.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\14.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\15.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\16.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\17.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\18.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\19.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\20.PNG" width="800" /></p><h3 id="feature-function">Feature Function</h3><p><img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\21.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\22.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\23.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\24.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\25.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\26.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\27.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\28.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\29.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\30.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\31.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\32.PNG" width="800" /></p><h2 id="proposed-method"><strong>Proposed Method</strong></h2><h3 id="models">Models</h3><p><img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\33.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\34.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\35.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\36.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\37.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\38.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\39.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\40.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\41.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\42.PNG" width="800" /></p><h3 id="lstm-crf-model">LSTM-CRF Model</h3><p><img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\43.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\44.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\45.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\46.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\47.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\48.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\49.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\50.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\51.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\52.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\53.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\54.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\55.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\56.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\57.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\58.PNG" width="800" /></p><h3 id="bi-lstm-crf-model">BI-LSTM-CRF Model</h3><p><img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\59.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\60.PNG" width="800" /></p><h2 id="experiments"><strong>Experiments</strong></h2><p><img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\61.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\62.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\63.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\64.PNG" width="800" /> <img data-proofer-ignore data-src="\assets\papers\Bidirectional LSTM-CRF Models for Sequence Tagging\65.PNG" width="800" /></p><h2 id="conclusions--reviews"><strong>Conclusions &amp; Reviews</strong></h2><ul><li><p>POS tagging과 같이 규칙이 있는 알고리즘일 경우 CRF를 사용하는 것이 의미가 있음 (예. 부사 뒤에 부사가 올 수 없음)</p><li><p>CRF의 feature function을 정의하기 위해서는 모든 경우의 수를 고려해야함</p><li><p>Feature function이 많아질수록 연산량이 많아 속도가 느려질 텐데 보통 몇 개인지 궁금함</p><li><p>CRF를 사용하면 속도가 많이 느려질 텐데 속도에 대한 실험 결과가 없어 아쉬움</p></ul><h2 id="reference"><strong>Reference</strong></h2></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/paper-reviews/'>Paper Reviews</a>, <a href='/categories/tagging/'>Tagging</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/lstm/" class="post-tag no-text-decoration" >LSTM</a> <a href="/tags/tagging/" class="post-tag no-text-decoration" >Tagging</a> <a href="/tags/nlp/" class="post-tag no-text-decoration" >NLP</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> <span class="text-muted small"></span></div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Paper Review. Bidirectional LSTM-CRF Models for Sequence Tagging@arXiv' 2015 - CV Researcher&url=https://joochann.github.io/posts/Bidirectional-LSTM-CRF-Models-for-Sequence-Tagging/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Paper Review. Bidirectional LSTM-CRF Models for Sequence Tagging@arXiv' 2015 - CV Researcher&u=https://joochann.github.io/posts/Bidirectional-LSTM-CRF-Models-for-Sequence-Tagging/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Paper Review. Bidirectional LSTM-CRF Models for Sequence Tagging@arXiv' 2015 - CV Researcher&url=https://joochann.github.io/posts/Bidirectional-LSTM-CRF-Models-for-Sequence-Tagging/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink('', '')" data-toggle="tooltip" data-placement="top" title=""> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/Bidirectional-LSTM-CRF-Models-for-Sequence-Tagging/">Paper Review. Bidirectional LSTM-CRF Models for Sequence Tagging@arXiv' 2015</a><li><a href="/posts/Fully-Convolutional-Networks-for-Semantic-Segmentation/">Paper Review. Fully Convolutional Networks for Semantic Segmentation@CVPR' 2015</a><li><a href="/posts/Arbitrary-Oriented-Scene-Text-Detection-via-Rotation-proposals/">Paper Review. Arbitrary-Oriented Scene Text Detection via Rotation proposals@IEEE Transactions on Multimedia' 2018</a><li><a href="/posts/EfficientDet-Scalable-and-Efficient-Object-Detection/">Paper Review. EfficientDet - Scalable and Efficient Object Detection@CVPR' 2020</a><li><a href="/posts/Learning-to-Reweight-Examples-for-Robust-Deep-Learning/">Paper Review. Learning to Reweight Examples for Robust Deep Learning@ICML' 2018</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/cv/">CV</a> <a class="post-tag" href="/tags/object-detection/">Object Detection</a> <a class="post-tag" href="/tags/deep-learning/">Deep Learning</a> <a class="post-tag" href="/tags/nlp/">NLP</a> <a class="post-tag" href="/tags/oriented-object-detection/">Oriented Object Detection</a> <a class="post-tag" href="/tags/probability/">Probability</a> <a class="post-tag" href="/tags/attention/">Attention</a> <a class="post-tag" href="/tags/machine-translation/">Machine Translation</a> <a class="post-tag" href="/tags/3d/">3D</a> <a class="post-tag" href="/tags/activity-recognition/">Activity Recognition</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/Attention-is-all-you-need/"><div class="card-body"> <span class="timeago small" >Sep 29, 2020<i class="unloaded">2020-09-29T14:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Paper Review. Attention is all you need@NIPS' 2017</h3><div class="text-muted small"><p> Paper link Abstract 당시 가장 좋은 모델은 Attention 메커니즘을 통해 encoder와 decoder를 연결한 모델이 성능이 가장 좋음 기존 모델들처럼 RNN또는 CNN을 사용하지 않고 attention 메커니즘만을 기반으로 하는 Transformer 모델을 제안함 기계 ...</p></div></div></a></div><div class="card"> <a href="/posts/Transformer-XL-Attentive-Language-Models-Beyond-a-Fixed-Length-Context/"><div class="card-body"> <span class="timeago small" >Nov 10, 2020<i class="unloaded">2020-11-10T14:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Paper Review. Transformer-XL Attentive Language Models Beyond a Fixed-Length Context@ACL' 2019</h3><div class="text-muted small"><p> Paper link Abstract 기존의 transformer는 고정된 개수(512)의 token들을 갖는 한 개의 segment만을 input으로 사용하여, 연속된 segment들 간의 dependency를 반영하지 못함 현재 segment를 처리할 때, 이전 segment를 처리할 때 계산된 hidden ...</p></div></div></a></div><div class="card"> <a href="/posts/Dynamic-Anchor-Learning-for-Arbitrary-Oriented-Object-Detection/"><div class="card-body"> <span class="timeago small" >Jan 20, 2021<i class="unloaded">2021-01-20T14:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Paper Review. Dynamic Anchor Learning for Arbitrary-Oriented Object Detection@AAAI' 2021</h3><div class="text-muted small"><p> Paper link Abstract 기존 모델들은 IoU를 적용하여 positive 와 negative 앵커를 샘플링을 함 Positive 앵커는 항상 정확한 탐지를 보장할 수 없지만, 일부 negative 앵커는 정확한 위치를 파악할 수 있음 이는 IoU를 통한 앵커의 품질 평가가 적절하지 ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/SlowFast-Networks-for-Video-Recognition/" class="btn btn-outline-primary" prompt="previous"><p>Paper Review. SlowFast Networks for Video Recognition@ICCV' 2019</p></a> <a href="/posts/Attention-is-all-you-need/" class="btn btn-outline-primary" prompt="next"><p>Paper Review. Attention is all you need@NIPS' 2017</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://twitter.com/username">JOOCHANN</a>. <span class="text-muted"></span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/cv/">CV</a> <a class="post-tag" href="/tags/object-detection/">Object Detection</a> <a class="post-tag" href="/tags/deep-learning/">Deep Learning</a> <a class="post-tag" href="/tags/nlp/">NLP</a> <a class="post-tag" href="/tags/oriented-object-detection/">Oriented Object Detection</a> <a class="post-tag" href="/tags/probability/">Probability</a> <a class="post-tag" href="/tags/attention/">Attention</a> <a class="post-tag" href="/tags/machine-translation/">Machine Translation</a> <a class="post-tag" href="/tags/3d/">3D</a> <a class="post-tag" href="/tags/activity-recognition/">Activity Recognition</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://joochann.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script>
