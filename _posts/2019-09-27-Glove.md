---
title: Glove(Global Vectors for Word Representation)
author: JooChan Park
date: 2019-09-27 19:00:00 +0800
categories: [Documentations, Deep Learning]
tags: [Deep Learning]
math: true
pin: true
---

## **Introduction**
GloVe(Global Vectors for Word Representation)는 count based와 direct predict를 모두 사용하는 방법론으로 2014년에 미국 스탠포드대학에서 개발한 단어 임베딩 방법론이다. Count based의 LSA(Latent Semantic Analysis)와 direct predict의 Word2Vec에 단점을 지적하며 이를 보완한다는 목적으로 나왔다. 실제로도 GloVe는 Word2Vec만큼이나 뛰어난 성능을 보여준다. 단정적으로 Word2Vec와 GloVe 중에서 어떤 것이 더 뛰어나다고 말할 수는 없고, 이 두 가지 전부를 사용해보고 성능이 더 좋은 것을 사용하는 것이 바람직하다고 한다.

## **Contents**
<img src='\assets\doc\Glove\Glove-1.png' width='900'>
<img src='\assets\doc\Glove\Glove-2.png' width='900'>
<img src='\assets\doc\Glove\Glove-3.png' width='900'>
<img src='\assets\doc\Glove\Glove-4.png' width='900'>
<img src='\assets\doc\Glove\Glove-5.png' width='900'>

## **Conclousion**
GloVe는 임베딩 된 center word와 context word 벡터의 내적이 전체 corpus에서의 co-occurrence probability가 되도록 만든 것 즉, count based의 장점과 direct predic-tion의 장점을 가져와서 기존 방법론의 단점을 보완한 것이 성능향상에 도움을 주었다고 생각한다.

## **Reference**
1.	https://wikidocs.net/book/2155
2.	https://ratsgo.github.io/ 
